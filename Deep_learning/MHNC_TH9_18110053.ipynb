{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MHNC_TH9_18110053.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# University of science\n",
        "## Advanced Machine Learning - Lab 09\n",
        "## Nguyễn Quốc Bảo - 18110053"
      ],
      "metadata": {
        "id": "mLtbGJVHGXe2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLGmFg7QxPSa"
      },
      "source": [
        "**LAB 09: REFORCEMENT LEARNING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPUcCnkgxfm6"
      },
      "source": [
        "1. Tìm hiểu về OpenAI\n",
        "2. Chơi thử trò SmartCar\n",
        "3. Làm quen với Naive và Q-Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dAqTNYhx146"
      },
      "source": [
        "* OpenAI là 1 công cụ được tạo ra nhằm giúp những nhà nghiên cứu dễ dàng hơn trong việc có 1 benchmark tốt bằng cách tạo một môi trường ổn định, có cách cài đặt đơn giản. Mục đích của công cụ này là giúp tăng khả năng reproduce lại các kết quả trong lĩnh vực AI, cũng như cung cấp 1 công cụ giúp chúng ta dễ dàng thao tác với các môi trường AI hơn. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKt5phSoAG0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ddb5f6-49b8-4c36-947b-2ff949a78c7f"
      },
      "source": [
        "#Cài đặt thư viện \n",
        "!pip install gym"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFluN8jFASrO"
      },
      "source": [
        "Chúng ta sẽ nói về một environment đơn giản, có số state và số action hữu hạn (và khá nhỏ) là Taxi-v2. Trong environment này, agent của chúng ta đóng vai trò 1 tài xế taxi. Có 4 địa điểm cố định khác nhau trên bản đồ (được ký hiệu R, G, Y, B), và mỗi khi environment bắt đầu, sẽ có 2 điểm bất kỳ là điểm đón và trả khách (2 điểm này có thể trùng nhau), cũng như vị trí của taxi cũng là vị trí bất kỳ. Nhiệm vụ của chúng ta là đón hành khách (ở điểm màu xanh da trời) và trả khách (ở điểm màu tím).\n",
        "\n",
        "Agent của chúng ta có thể thực hiện 6 actions:\n",
        "\n",
        "0: xuống dưới\n",
        "\n",
        "1: lên trên\n",
        "\n",
        "2: sang trái\n",
        "\n",
        "3: sang phải\n",
        "\n",
        "4: đón khách\n",
        "\n",
        "5: trả khách\n",
        "\n",
        "Reward của environment này được tính như sau:\n",
        "\n",
        "cứ sau 1 time step (tức là khi xảy ra bất kỳ action nào), sẽ nhận -1 reward\n",
        "nhận được +20 reward nếu ta trả khách thành công (nghĩa là time step đó ta sẽ nhận +19 reward)\n",
        "nếu agent có hành vi đón khách và trả khách không hợp lệ, nhận -10 reward (nghĩa là time step đó ta sẽ nhận -11 reward).\n",
        "\n",
        "taxi sẽ hoạt động trên một khu vực 5x5, với 4 điểm trả khác và 5 địa điểm hành khách đang đứng nên số states sẽ là 5x5x5x4=500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkAJ7c3wCB_j"
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import time\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK4uhv_ZAvar",
        "outputId": "bbac0b3a-8bba-4483-b34d-6a3f62f31648"
      },
      "source": [
        "env = gym.make(\"Taxi-v3\") #Gọi môi trường ra\n",
        "env.env.s=env.encode(1,1,2,0)\n",
        "env.render()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: | : :G|\n",
            "| :\u001b[43m \u001b[0m| : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[34;1mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9shg8mBWA2-h"
      },
      "source": [
        "Hành khách có thể ở 5 điểm là R, G, Y, B và trong xe, màu xanh dương để chỉ địa điểm hành khách đang đứng chờ (nếu hành khác trong taxi thì xe sẽ màu xanh lá), màu tím để chỉ địa điểm cần chở khách đến"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0ByBeA1BfsL",
        "outputId": "561790a2-78e6-41b2-a894-32e302a7ede1"
      },
      "source": [
        "env.env.s=env.encode(2,2,4,1)\n",
        "env.render()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : :\u001b[42m_\u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO3XzAmVBrAa"
      },
      "source": [
        "ta sẽ dùng env.encode(số_hàng,số_cột,hành_khách,điểm_trả_khách), với:\n",
        "* số_hàng thuộc [0,1,2,3,4]\n",
        "* số_cột thuộc  [0,1,2,3,4]\n",
        "* hành_khách: 0 là ở R, 1 là ở G, 2 là ở Y, 3 là ở B, 4 là trên xe\n",
        "* điểm_trả_khách: 0 là ở R, 1 là ở G, 2 là ở Y, 3 là ở B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8aRFBl4EF1J"
      },
      "source": [
        "#Naive-Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w-poHgtddc3"
      },
      "source": [
        "Bây giờ ta sẽ học Q-table một cách ngây thơ :\n",
        "\n",
        "* Chọn hành động tốt nhất dựa vào những gì đã học\n",
        "* Nếu điểm bằng nhau thì chọn ngẫu nhiên\n",
        "* Q-table cập nhất với discount = 0 (không xem xét tương lai)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWLkda4pETSu"
      },
      "source": [
        "Đầu tiên ta phải tạo ra một q-table là ma trận $size\\_state\\times size\\_action$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMwLsuyc2k3"
      },
      "source": [
        "state_size = env.observation_space.n\n",
        "action_size = env.action_space.n\n",
        "\n",
        "q_table = np.zeros((state_size, action_size))\n",
        "\n",
        "FILE_SAVE_Naive = \"q_table_naive.npy\"\n",
        "total_episodes = 5000       # Total episodes\n",
        "total_test_episodes = 100     # Total test episodes\n",
        "max_steps = 99                # Max steps per episode\n",
        "           # Exponential decay rate for exploration prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGOCGE3ec83M",
        "outputId": "b72fc2ff-38b9-4435-de7b-bd1d9e51615c"
      },
      "source": [
        "import time\n",
        "for episode in range(total_episodes):\n",
        "    state = env.reset()   # reset lại môi trường\n",
        "    done = False          # đã hoàn thành trả khách hay chưa\n",
        "    for step in range(max_steps):\n",
        "        clear_output(wait=True)\n",
        "        print(\"episode: \",episode)\n",
        "        if  np.max(q_table[state]) ==0:         # nếu trong state q_value đều bằng 0 thì chọn đại 1 action\n",
        "            action=np.random.randint(0,action_size)\n",
        "        else:\n",
        "            action = np.argmax(q_table[state])  # chọn action có q_value lớn nhất\n",
        "\n",
        "        new_state, reward, done, _ = env.step(action)   # thực hiện hành động để nhận reward và state, action mới\n",
        "\n",
        "        q_table[state,action] += reward # cập nhật q_table\n",
        "        state = new_state\n",
        "        if done:       # nếu taxi có hành vi trả khách thì kết thúc episode\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode:  4999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moGEPh_fMeTc"
      },
      "source": [
        "# lưu lại q_table\n",
        "np.save(FILE_SAVE_Naive,q_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js8wTRHUMejA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f404def2-3713-4047-ab69-e49811ed7235"
      },
      "source": [
        "# từ q_table bắt đầu chơi thử\n",
        "q_table=np.load(\"q_table_naive.npy\")\n",
        "rewards = []\n",
        "\n",
        "for episode in range(total_test_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards = 0\n",
        "    \n",
        "\n",
        "    for step in range(max_steps):\n",
        "        print(\"****************************************************\")\n",
        "        print(\"EPISODE \", episode)\n",
        "        action = np.argmax(q_table[state,:])\n",
        "        \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        env.render() # hiển thị trò chơi\n",
        "        total_rewards += reward\n",
        "        print(total_rewards)\n",
        "        time.sleep(0.5)\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        if done:\n",
        "            rewards.append(total_rewards)\n",
        "            #print (\"Score\", total_rewards)\n",
        "            break\n",
        "        state = new_state\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score over time: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()\n",
        "print (\"Score over time: \" +  str(sum(rewards)/total_test_episodes))"
      ],
      "metadata": {
        "id": "CVw4khJPWSn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpFMeqWHD-XW",
        "outputId": "3938497b-0714-43a1-f1da-0045721d630a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0.,    0.,    0.,    0.,    0.,    0.],\n",
              "       [-251., -251., -251., -250., -250., -250.],\n",
              "       [-208., -208., -208., -208., -208., -210.],\n",
              "       ...,\n",
              "       [-124., -124., -123., -123., -130., -130.],\n",
              "       [-141., -141., -140., -140., -140., -140.],\n",
              "       [ -20.,  -20.,  -19.,  -19.,  -20.,  -30.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SYLNclrdVJn"
      },
      "source": [
        "# Q-Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGXLLkkBdYYT"
      },
      "source": [
        "Giá trị Q-value được cập nhật như sau:$$Q(s_t, a_t) = Q(s_t, a_t) + \\alpha [r_{t+1} + \\lambda \\max_{a}Q(s_{t+1}, a) - Q(s_t, a_t)]$$với $\\alpha$ là learning rate, $\\lambda$ là discount rate, $s_t$ là quan sát thời điểm $t$ và $r_{t+1}$ là phần thưởng sau khi thực hiện hành động $a_t$ với quan sát $s_t$.\n",
        "\n",
        "Ngoài ra agent sẽ ngẫu nhiên thực hiện exploration với xác suất nào đó ở những state ban đầu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Taxi-v3\")\n",
        "state_size = env.observation_space.n\n",
        "print(state_size)\n",
        "action_size = env.action_space.n\n",
        "print(action_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0Jza3Sjd4SC",
        "outputId": "e8d9ba2e-4115-460d-8a6b-f1ef001a2737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvs2PFgGo2Bt"
      },
      "source": [
        "\n",
        "env = gym.make(\"Taxi-v3\")\n",
        "state_size = env.observation_space.n\n",
        "action_size = env.action_space.n\n",
        "\n",
        "q_table = np.zeros((state_size, action_size))\n",
        "\n",
        "FILE_SAVE_Qlearning = \"q_table_qlearning.npy\"\n",
        "total_episodes = 5000         # Total episodes\n",
        "total_test_episodes = 10    # Total test episodes\n",
        "max_steps = 99                # Max steps per episode\n",
        "\n",
        "learning_rate = 0.7           # Learning rate\n",
        "discount_rate = 0.95         # Discounting rate\n",
        "\n",
        "# Exploration parameters\n",
        "epsilon = 1.0                 # Exploration rate\n",
        "max_epsilon = 1.0             # Exploration probability at start\n",
        "min_epsilon = 0.01            # Minimum exploration probability \n",
        "decay_rate = 0.01             # Exponential decay rate for exploration prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AcIuKE0aZMg",
        "outputId": "2a5bf53f-a933-43db-b608-3911de39a80d"
      },
      "source": [
        "q_table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqAMf8YYevFC",
        "outputId": "0bcd43e7-6637-45bc-8b00-a18723f102da"
      },
      "source": [
        "import time\n",
        "for episode in range(total_episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    clear_output(wait=True)\n",
        "    print(\"episode: \",episode)\n",
        "    for step in range(max_steps):\n",
        "        #clear_output(wait=True)\n",
        "        \n",
        "        epsilon = min(min_epsilon, epsilon*decay_rate)\n",
        "        # kiểm tra xem agent dùng exploi hay explor\n",
        "        if np.random.rand() < epsilon:\n",
        "            # exploration\n",
        "            action = np.random.randint(0, action_size)\n",
        "        else:\n",
        "            # exploitation\n",
        "            if np.max(q_table[state]) == 0:\n",
        "                action=np.random.randint(0,action_size)\n",
        "            else:\n",
        "                action = np.argmax(q_table[state])\n",
        "            \n",
        "        # nhận reward và state tiếp theo\n",
        "        new_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        # cập nhật q_table theo Bellman equation\n",
        "        update = reward + discount_rate*q_table[new_state].max() - q_table[state,action]\n",
        "        q_table[state,action] = q_table[state,action] + learning_rate*update\n",
        "        state = new_state\n",
        "        if done:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode:  4999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKiSW-mMf_Wd"
      },
      "source": [
        "# lưu lại q_table\n",
        "np.save(FILE_SAVE_Qlearning,q_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pvzBTLvgL8P",
        "outputId": "6b79789c-9217-45c1-a657-025935d233e9"
      },
      "source": [
        "# từ q_table bắt đầu chơi thử\n",
        "#q_table = np.load(\"q_table_qlearning.npy\")\n",
        "rewards = []\n",
        "\n",
        "for episode in range(total_test_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards = 0\n",
        "    \n",
        "\n",
        "    for step in range(max_steps):\n",
        "        print(\"****************************************************\")\n",
        "        print(\"EPISODE \", episode)\n",
        "        \n",
        "        action = np.argmax(q_table[state,:])\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        env.render() # hiển thị trò chơi\n",
        "        total_rewards += reward\n",
        "        print(total_rewards)\n",
        "        time.sleep(0.5)\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        if done:\n",
        "            rewards.append(total_rewards)\n",
        "            #print (\"Score\", total_rewards)\n",
        "            break\n",
        "        state = new_state\n",
        "        \n",
        "# env.close()\n",
        "# print (\"Score over time: \" +  str(sum(rewards)/total_test_episodes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************\n",
            "EPISODE  9\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | :\u001b[43m \u001b[0m|\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "-99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ66Q0YiUC9l",
        "outputId": "9a48aebc-4919-4132-fd23-8ec6fd21624d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ],\n",
              "       [-5.46566072, -5.64429798, -5.6077611 , -5.48637774,  5.20997639,\n",
              "        -7.        ],\n",
              "       [-4.78898712, -4.5840672 , -4.47236866, -4.41448387, 10.9512375 ,\n",
              "        -9.73      ],\n",
              "       ...,\n",
              "       [-2.65639999, -2.37968605, -2.22291475, -2.79375875, -9.919     ,\n",
              "        -9.9757    ],\n",
              "       [-4.6502047 , -4.72978337, -4.5840672 , -4.81579966, -7.        ,\n",
              "        -7.        ],\n",
              "       [ 0.        , -0.7       ,  0.        , 18.        , -9.1       ,\n",
              "        -7.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqLhCQdVltdm"
      },
      "source": [
        "#Bài tập"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc29B4SZlvxt"
      },
      "source": [
        "1. Giải thích vì sao khi dùng Naive-Learning thì xe taxi chỉ đứng yên một chỗ?\n",
        "2. Giải thích vì sao khi dùng Q-Leaning thì xe taxi có thể đón và trả khách được?\n",
        "3. Tìm hiểu một game khác trên OpenAI và thiết lập cho agent chơi được"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hjajX_yKm1R"
      },
      "source": [
        "1. Khi dùng Naive-Learning\n",
        "\n",
        "Vì thực hiện các action chỉ lựa chọn theo giá trị tốt nhất và chỉ khi giá trị q-value tại state đó đều bằng 0 thì agent sẽ chọn action một cách ngẫu nhiên, nên trường hợp agent bị đứng yên là do khi đó giá trị hiện tại đang là tốt nhất nên nó sẽ chọn state đó.\n",
        "\n",
        "2. Khi dùng Q-Leaning\n",
        "\n",
        "Chia ra 2 trường hợp exploitation (lựa chọn action tốt nhất) và exploration (chọn action một cách ngẫu nhiên), ban đầu agent sẽ cố gắng exploration nhiều nhất có thể để có các giá trị reward và state value tương ứng. Sau đó mới chuyển sang exploitation để tối ưu các action tốt nhất. Chính vì thế khác với Naive-leaning, giai đoạn ban đầu thực hiện exploration nhiều action và cố gắng exploiration về sau đạt được reward tốt nhất nên có thể đón và trả khách.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\n",
        "\n",
        "Car_Pole là một con lắc có trọng tâm nằm trên điểm quay của nó. Nó không ổn định, nhưng có thể được kiểm soát bằng cách di chuyển điểm trục xuống dưới tâm khối lượng. Mục đích là để giữ cân bằng cartpole bằng cách tác dụng các lực thích hợp lên một điểm trục.\n",
        "\n",
        "Cột được gắn bằng một khớp vào xe đẩy, khớp này di chuyển dọc theo đường ray. Hệ thống được điều khiển bằng cách tác dụng một lực theo hướng trái hoặc phải vào giỏ hàng. Con lắc bắt đầu thẳng đứng, và mục đích là ngăn nó rơi xuống. Phần thưởng +1 được cung cấp cho mỗi bước thời gian mà cột vẫn thẳng đứng. Tập kết thúc khi cột lệch hơn 15 độ so với phương thẳng đứng hoặc xe đẩy cách tâm hơn 2,4 đơn vị. Khi reward >195 chúng ta cũng sẽ kết thúc việc huấn luyện\n",
        "\n",
        "actions ở một state chính là 2 là lực tác động vào trò chơi theo hướng phải hay hướng trái."
      ],
      "metadata": {
        "id": "Sr3ITwIgf83Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "D0i-h5-JtdY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "cl4GelTDtdON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay"
      ],
      "metadata": {
        "id": "jqe0jZU7tdCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 400))\n",
        "display.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjS7AsHfthL6",
        "outputId": "7cc320cb-49df-461b-e425-5aea1ba68c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fb901081110>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "env.reset()\n",
        "prev_screen = env.render(mode='rgb_array')\n",
        "plt.imshow(prev_screen)\n",
        "\n",
        "for i in range(50):\n",
        "  action = env.action_space.sample()\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  screen = env.render(mode='rgb_array')\n",
        "  \n",
        "  plt.imshow(screen)\n",
        "  ipythondisplay.clear_output(wait=True)\n",
        "  ipythondisplay.display(plt.gcf())\n",
        "\n",
        "  if done:\n",
        "    break\n",
        "    \n",
        "ipythondisplay.clear_output(wait=True)\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "OFWbaBH3tg9L",
        "outputId": "d457ebd9-424c-4543-fd46-d192ac9e4992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwJKqARutgvU",
        "outputId": "8d8a16f0-be25-4a52-8d81-7f4fd1cc8a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f3453496cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.1\n",
        "FILE_SAVE_Qlearning = \"CartPole_q_table_qlearning.npy\"\n",
        "DISCOUNT = 0.95\n",
        "EPISODES = 20000\n",
        "total = 0\n",
        "total_reward = 0\n",
        "prior_reward = 0\n",
        "\n",
        "Observation = [30, 30, 50, 50]\n",
        "np_array_win_size = np.array([0.25, 0.25, 0.01, 0.1])\n",
        "\n",
        "epsilon = 1\n",
        "\n",
        "epsilon_decay_value = 0.99995\n",
        "test_episodes = 10"
      ],
      "metadata": {
        "id": "41d1HrzhoHfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_table = np.random.uniform(low=0, high=1, size=(Observation + [env.action_space.n]))\n",
        "q_table.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa38cz3IoKI8",
        "outputId": "12c4809c-cdff-44c8-b781-5dfe2068b208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 30, 50, 50, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discrete_state(state):\n",
        "    discrete_state = state/np_array_win_size+ np.array([15,10,1,10])\n",
        "    return tuple(discrete_state.astype(np.int))"
      ],
      "metadata": {
        "id": "wfcp1-AuoMpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for episode in range(EPISODES + 1): # go through the episodes\n",
        "    t0 = time.time() # set the initial time\n",
        "    discrete_state = get_discrete_state(env.reset()) # get the discrete start for the restarted environment \n",
        "    done = False\n",
        "    episode_reward = 0 # reward starts as 0 for each episode\n",
        "\n",
        "    if episode % 2000 == 0: \n",
        "        print(\"Episode: \" + str(episode))\n",
        "\n",
        "    while not done: \n",
        "\n",
        "        if np.random.random() > epsilon:\n",
        "            # exploitation\n",
        "            action = np.argmax(q_table[discrete_state]) # take cordinated action\n",
        "        else:\n",
        "            # exploration\n",
        "            action = np.random.randint(0, env.action_space.n) # do a random ation\n",
        "\n",
        "        new_state, reward, done, _ = env.step(action) # step action to get new states, reward, and the \"done\" status.\n",
        "\n",
        "        episode_reward += reward # add the reward\n",
        "\n",
        "        new_discrete_state = get_discrete_state(new_state)\n",
        "\n",
        "        if episode % 2000 == 0: # render\n",
        "            env.render()\n",
        "\n",
        "        if not done: # update q-table\n",
        "            max_future_q = np.max(q_table[new_discrete_state])\n",
        "\n",
        "            current_q = q_table[discrete_state + (action,)]\n",
        "\n",
        "            new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * (reward + DISCOUNT * max_future_q)\n",
        "\n",
        "            q_table[discrete_state + (action,)] = new_q\n",
        "\n",
        "        discrete_state = new_discrete_state\n",
        "\n",
        "    if epsilon > 0.05: # epsilon modification\n",
        "        if episode_reward > prior_reward and episode > 10000:\n",
        "            epsilon = math.pow(epsilon_decay_value, episode - 10000)\n",
        "\n",
        "            if episode % 500 == 0:\n",
        "                print(\"Epsilon: \" + str(epsilon))\n",
        "\n",
        "    t1 = time.time() # episode has finished\n",
        "    episode_total = t1 - t0 # episode total time\n",
        "    total = total + episode_total\n",
        "\n",
        "    total_reward += episode_reward # episode total reward\n",
        "    prior_reward = episode_reward\n",
        "\n",
        "    if episode % 1000 == 0: # every 1000 episodes print the average time and the average reward\n",
        "        mean = total / 1000\n",
        "        print(\"Time Average: \" + str(mean))\n",
        "        total = 0\n",
        "\n",
        "        mean_reward = total_reward / 1000\n",
        "        print(\"Mean Reward: \" + str(mean_reward))\n",
        "        total_reward = 0\n"
      ],
      "metadata": {
        "id": "_lyn3AqJnxBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bff242-9894-4dd5-ad5f-8d67911d8414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0\n",
            "Time Average: 0.00011224603652954101\n",
            "Mean Reward: 0.017\n",
            "Time Average: 0.0009931690692901612\n",
            "Mean Reward: 22.354\n",
            "Episode: 2000\n",
            "Time Average: 0.0009659392833709717\n",
            "Mean Reward: 21.671\n",
            "Time Average: 0.000949415922164917\n",
            "Mean Reward: 21.824\n",
            "Episode: 4000\n",
            "Time Average: 0.000975822925567627\n",
            "Mean Reward: 22.246\n",
            "Time Average: 0.0009504084587097168\n",
            "Mean Reward: 22.19\n",
            "Episode: 6000\n",
            "Time Average: 0.0009934237003326415\n",
            "Mean Reward: 22.932\n",
            "Time Average: 0.000912360429763794\n",
            "Mean Reward: 22.11\n",
            "Episode: 8000\n",
            "Time Average: 0.000960597276687622\n",
            "Mean Reward: 22.113\n",
            "Time Average: 0.0009566988945007325\n",
            "Mean Reward: 22.192\n",
            "Episode: 10000\n",
            "Time Average: 0.0009985804557800294\n",
            "Mean Reward: 22.25\n",
            "Epsilon: 0.9512282354250458\n",
            "Time Average: 0.0009996068477630615\n",
            "Mean Reward: 23.381\n",
            "Episode: 12000\n",
            "Time Average: 0.0010502233505249024\n",
            "Mean Reward: 23.512\n",
            "Epsilon: 0.8824941446941661\n",
            "Time Average: 0.0011073687076568603\n",
            "Mean Reward: 24.688\n",
            "Epsilon: 0.8394533480303666\n",
            "Episode: 14000\n",
            "Time Average: 0.00119771409034729\n",
            "Mean Reward: 26.901\n",
            "Epsilon: 0.7985117269685725\n",
            "Time Average: 0.00120383620262146\n",
            "Mean Reward: 27.311\n",
            "Epsilon: 0.7595669010105212\n",
            "Episode: 16000\n",
            "Time Average: 0.001357741117477417\n",
            "Mean Reward: 30.261\n",
            "Epsilon: 0.7225214829355084\n",
            "Epsilon: 0.7046819235193919\n",
            "Time Average: 0.0014250969886779785\n",
            "Mean Reward: 31.759\n",
            "Epsilon: 0.687282835269431\n",
            "Episode: 18000\n",
            "Epsilon: 0.6703133426452782\n",
            "Time Average: 0.0016549172401428222\n",
            "Mean Reward: 35.911\n",
            "Epsilon: 0.6537628386312633\n",
            "Time Average: 0.001703510046005249\n",
            "Mean Reward: 38.561\n",
            "Episode: 20000\n",
            "Time Average: 0.0018897240161895752\n",
            "Mean Reward: 41.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lưu lại q_table\n",
        "np.save(FILE_SAVE_Qlearning,q_table)"
      ],
      "metadata": {
        "id": "ARm4Q0IJY2fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# từ q_table bắt đầu chơi thử\n",
        "#q_table = np.load(\"CartPole_q_table_qlearning.npy\")\n",
        "rewards = []\n",
        "\n",
        "for episode in range(test_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards = 0\n",
        "    \n",
        "\n",
        "    for step in range(100):\n",
        "        print(\"****************************************************\")\n",
        "        print(\"EPISODE \", episode)\n",
        "        \n",
        "        ##########\n",
        "        action = env.action_space.sample()\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        total_rewards += reward\n",
        "        print(total_rewards)\n",
        "        time.sleep(0.01)\n",
        "        screen = env.render(mode='rgb_array')\n",
        "\n",
        "        plt.imshow(screen)\n",
        "        ipythondisplay.clear_output(wait=True)\n",
        "        ipythondisplay.display(plt.gcf())\n",
        "        \n",
        "        if done:\n",
        "            rewards.append(total_rewards)\n",
        "            # print (\"Score\", total_rewards)\n",
        "            break\n",
        "        state = new_state\n",
        "        \n",
        "env.close()\n",
        "# print (\"Score over time: \" +  str(sum(rewards)/test_episodes))"
      ],
      "metadata": {
        "id": "Io-IvK-U5ldT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "0cc3a69b-a335-4592-8272-ec1a99ba2c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************\n",
            "EPISODE  9\n",
            "25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lxAK4Q97CWGU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}