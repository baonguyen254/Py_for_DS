{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khoa Học Tự Nhiên\n",
    "## Lab 8 - ML - Backpropagation\n",
    "### Nguyễn Quốc Bảo - 18110053"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j411dkkAuSvt"
   },
   "source": [
    "**Lab-08: Backpropagation**\n",
    "\n",
    "Trong bài thực hành này chúng ta sẽ thử cài đặt Backpropagation \n",
    "\n",
    "Ta muốn dựa vào 2 chiều của lá, phân biệt giữa loại lá 1 và loại lá 2. Cụ thể, với $x = (x_1,x_2, 1)$ là input, ta muốn đoán một phân phối\n",
    "    $$ P_\\theta(c|x),c = 0, 1 $$\n",
    "với $\\theta$ là các tham số\n",
    "Ta mô hình $P_\\theta$ là một neural network có 2 lớp ẩn, mỗi lớp 5 neurons, tức là\\n\",\n",
    "    $$ P_\\theta(c|x) = \\text{softmax}(\\max(0, \\max(0, x \\cdot W_1 + b_1) \\cdot W_2 + b_2) \\cdot W_3 + b_3 )$$\n",
    "\n",
    "với $x$ là vector dòng $[[x_1, x_2]]$ kích thước $ 1\\times 2$, $W_1, W_2, W_3$ là các ma trận có kích thước $2 \\times 5, 5 \\times 5, 5 \\times 3$, và $b_1, b_2, b_3$ là các ma trận kích thước $1 \\times 5, 1 \\times 5, 1 \\times 3$.\n",
    "\n",
    "Khi đó $P(c|x)$ là một vector dòng độ dài 3, xem như $P(c|x)= (P_1(c|x), P_2(c|x), P_3(c|x)) = (P(c=0|x), P(c=1|x), P(c=2|x))$\n",
    "Bộ các ma trận $\\\\theta = (W_1, W_2, W_3, b_1, b_2, b_3)$ chính là tham số cần tìm của model. Giờ cần tìm $\\\\theta$ sao cho \n",
    "\n",
    "$$ L = \\frac{1}{N} \\sum_{x,y} - y_0 \\log P_\\theta(0|x) -  y_1 \\log P_\\theta(1|x) - y_2 \\log P_\\theta(2|x) $$\n",
    "\n",
    "đạt giá trị nhỏ nhất với $y = (y_0, y_1, y_2)$ là one-hot vector biểu thị loại lá tương ứng với $x$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSZlBMhnewyH"
   },
   "source": [
    "# Bài Tập\n",
    "1. Từ code demo hãy cài đặt thêm một module để chọn ra được bộ weights sao cho accuracy trên tập validation là tốt nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hRjcNaFBigAx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zS_ADnTigA3"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DzecGvNIigA4"
   },
   "outputs": [],
   "source": [
    "def one_hot_vector(y):\n",
    "    out = np.zeros((y.shape[0], max(y)+1))\n",
    "    for i in range(y.shape[0]):\n",
    "        out[i, y[i]] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NpL3fpASigA5"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"https://raw.githubusercontent.com/huynhthanh98/ML/master/lab-08/bt_train.csv\")\n",
    "valid = pd.read_csv(\"https://raw.githubusercontent.com/huynhthanh98/ML/master/lab-08/bt_valid.csv\")\n",
    "\n",
    "x1_train = train[\"x1\"].values\n",
    "x2_train = train[\"x2\"].values\n",
    "y_train = train[\"label\"].values\n",
    "\n",
    "x1_valid = valid['x1'].values\n",
    "x2_valid = valid['x2'].values\n",
    "y_valid = valid['label'].values\n",
    "\n",
    "# normalize\n",
    "x1_mean = np.mean(x1_train)\n",
    "x1_std = np.std(x1_train)\n",
    "x2_mean = np.mean(x2_train)\n",
    "x2_std = np.std(x2_train)\n",
    "\n",
    "x1_train = (x1_train - x1_mean)/ x1_std\n",
    "x2_train = (x2_train - x2_mean)/ x2_std\n",
    "\n",
    "x1_valid = (x1_valid - x1_mean)/ x1_std\n",
    "x2_valid = (x2_valid - x2_mean)/ x2_std\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.concatenate([x1_train.reshape(-1,1), x2_train.reshape(-1,1)], axis=1)\n",
    "y_train = one_hot_vector(y_train)\n",
    "\n",
    "X_valid = np.concatenate([x1_valid.reshape(-1,1), x2_valid.reshape(-1,1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 3) (300, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4_CidQJtigA7"
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "W1 = np.random.randn(2,5)\n",
    "W2 = np.random.randn(5,5)\n",
    "W3 = np.random.randn(5,3)\n",
    "\n",
    "b1 = np.random.randn(1,5)\n",
    "b2 = np.random.randn(1,5)\n",
    "b3 = np.random.randn(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Kw8mSDk6igA9"
   },
   "outputs": [],
   "source": [
    "def relu(h):\n",
    "    return np.array([max(0,i) for i in h.reshape(-1)]).reshape(h.shape)\n",
    "\n",
    "def softmax(z):\n",
    "    return np.exp(z)/ np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def CrossEntropy(o,y):\n",
    "    return - np.sum(y*np.log(o))\n",
    "\n",
    "def predict(X_valid,y_valid , W1, b1, W2, b2, W3, b3):\n",
    "    z1_valid = np.dot(X_valid, W1) + b1\n",
    "    o1_valid = relu(z1_valid)\n",
    "\n",
    "    z2_valid = np.dot(o1_valid, W2) + b2\n",
    "    o2_valid = relu(z2_valid)\n",
    "\n",
    "    z3_valid = np.dot(o2_valid, W3) + b3\n",
    "    o3_valid = softmax(z3_valid)\n",
    "    \n",
    "    accuracy = np.sum(np.argmax(o3_valid, axis = 1) == y_valid)/ y_valid.shape[0]\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "ln = 0.001\n",
    "N = y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vjLI8EDoigA-"
   },
   "outputs": [],
   "source": [
    "ls_loss = []\n",
    "store = dict()\n",
    "for epochs in range(10000):\n",
    "    # foward\n",
    "    z1 = np.dot(X_train, W1) + b1\n",
    "    o1 = relu(z1)\n",
    "\n",
    "    z2 = np.dot(o1, W2) + b2\n",
    "    o2 = relu(z2)\n",
    "\n",
    "    z3 = np.dot(o2, W3) + b3\n",
    "    o3 = softmax(z3)\n",
    "    \n",
    "    Parameter = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2, 'W3': W3, 'b3': b3}\n",
    "    accuracy = predict(X_valid, y_valid , W1, b1, W2, b2, W3, b3)\n",
    "    store[accuracy] = Parameter\n",
    "   \n",
    "    # backpropagation\n",
    "    dL_dz3 = 1/len(X_train)*(o3 - y_train) \n",
    "    dL_dW3 = np.dot(o2.T, dL_dz3)    \n",
    "    dL_db3 = np.sum(dL_dz3, axis = 0)\n",
    "\n",
    "\n",
    "    dL_do2 = np.dot(dL_dz3, W3.T)\n",
    "    dL_dz2 = dL_do2.copy()\n",
    "    dL_dz2[z2 < 0] = 0\n",
    "    dL_dW2 = np.dot(o1.T,dL_dz2)\n",
    "    dL_db2 = np.sum(dL_dz2, axis = 0)\n",
    "\n",
    "    dL_do1 = np.dot(dL_dz2, W2.T)\n",
    "    dL_dz1 = dL_do1.copy()\n",
    "    dL_dz1[z1 < 0] = 0\n",
    "    dL_dW1 = np.dot(X_train.T, dL_dz1)\n",
    "    dL_db1 = np.sum(dL_dz1, axis = 0)\n",
    "\n",
    "    W3 -= ln* dL_dW3\n",
    "    b3 -= ln* dL_db3\n",
    "    W2 -= ln* dL_dW2\n",
    "    b2 -= ln* dL_db2\n",
    "    W1 -= ln* dL_dW1\n",
    "    b1 -= ln* dL_db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6633333333333333\n",
      "Parameter:  {'W1': array([[ 0.02694447, -0.7906416 ,  0.3302676 ,  2.35072935,  1.36882669],\n",
      "       [ 0.58438011,  0.38741171,  0.50252065,  0.03250823,  1.26698177]]), 'b1': array([[-0.97044389,  0.08331571,  0.26254916,  0.78149445,  0.46839515]]), 'W2': array([[ 0.48025174, -0.61985499,  0.96069146, -1.96437687,  0.41398502],\n",
      "       [-1.32433466, -0.91175675,  0.73369779, -1.79556679, -1.76457783],\n",
      "       [-1.23224983, -0.93832586, -0.0466786 ,  0.48377297,  0.63710807],\n",
      "       [-1.39352776,  0.28487368, -1.11022537,  0.69753778,  0.42563566],\n",
      "       [ 1.24757854,  0.25826951, -2.12480102,  0.97396357, -2.28130296]]), 'b2': array([[ 0.3392448 ,  0.77882641,  0.60510154, -0.23496288, -1.1806147 ]]), 'W3': array([[ 0.40194578,  0.11485569, -0.58658745],\n",
      "       [-1.81281847,  1.08732044, -0.23196456],\n",
      "       [-0.59930622, -0.75246117, -1.08292404],\n",
      "       [ 0.09991397, -0.4170902 ,  1.0432869 ],\n",
      "       [-1.39083156, -1.64351731, -0.87444904]]), 'b3': array([[ 0.37379614, -0.52107513, -1.21761842]])}\n"
     ]
    }
   ],
   "source": [
    "store = list(sorted(store.items(), reverse=True , key = lambda t: t[0]))\n",
    "accuracy, Parameter = store[0]\n",
    "print('accuracy :', accuracy)\n",
    "print('Parameter: ',Parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "2. Từ bộ dữ liệu bên dưới hãy cài đặt backpropagation cho bài toán phân biệt ung thư vú. Hãy tự chọn số layers và số nodes mà mình cho là thích hợp, cũng như là nêu ra số layers và số nodes của mỗi layer mà mình đã chọn. Tính accuracy trên tập training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1NscLiyVYuPx"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "X = breast_cancer.data  \n",
    "y = breast_cancer.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_mean=np.mean(X_train)\n",
    "X_std=np.std(X_train)\n",
    "\n",
    "X_valid=(X_valid-X_mean)/X_std\n",
    "X_train=(X_train-X_mean)/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers_size):\n",
    "        self.layers_size = layers_size\n",
    "        self.parameters = {}\n",
    "        self.L = len(self.layers_size)\n",
    "        self.n = 0\n",
    "        self.costs = []\n",
    "    \n",
    "    def initialize_parameters(self):\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        for l in range(1, len(self.layers_size)):\n",
    "            self.parameters[\"W\" + str(l)] = np.random.randn(self.layers_size[l], \n",
    "                                        self.layers_size[l - 1]) / np.sqrt(self.layers_size[l - 1])\n",
    "            self.parameters[\"b\" + str(l)] = np.zeros((self.layers_size[l], 1))\n",
    "    def forward(self, X):\n",
    "        store = {}\n",
    " \n",
    "        O = X.T\n",
    "        for l in range(self.L - 1):\n",
    "            Z = self.parameters[\"W\" + str(l + 1)].dot(O) + self.parameters[\"b\" + str(l + 1)]\n",
    "            O = self._sigmoid(Z)\n",
    "            store[\"O\" + str(l + 1)] = O\n",
    "            store[\"W\" + str(l + 1)] = self.parameters[\"W\" + str(l + 1)]\n",
    "            store[\"Z\" + str(l + 1)] = Z\n",
    " \n",
    "        Z = self.parameters[\"W\" + str(self.L)].dot(O) + self.parameters[\"b\" + str(self.L)]\n",
    "        O = self._sigmoid(Z)\n",
    "        store[\"O\" + str(self.L)] = O\n",
    "        store[\"W\" + str(self.L)] = self.parameters[\"W\" + str(self.L)]\n",
    "        store[\"Z\" + str(self.L)] = Z\n",
    " \n",
    "        return O, store\n",
    "    \n",
    "    def _sigmoid(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def _sigmoid_derivative(self, Z):\n",
    "        s = 1 / (1 + np.exp(-Z))\n",
    "        return s * (1 - s)\n",
    " \n",
    "    def backward(self, X, Y, store):\n",
    " \n",
    "        derivatives = {}\n",
    " \n",
    "        store[\"O0\"] = X.T\n",
    " \n",
    "        O = store[\"O\" + str(self.L)]\n",
    "        dO = -np.divide(Y, O) + np.divide(1 - Y, 1 - O)\n",
    " \n",
    "        dZ = dO * self._sigmoid_derivative(store[\"Z\" + str(self.L)])\n",
    "        dW = dZ.dot(store[\"O\" + str(self.L - 1)].T) / self.n\n",
    "        db = np.sum(dZ, axis=1, keepdims=True) / self.n\n",
    "        dAPrev = store[\"W\" + str(self.L)].T.dot(dZ)\n",
    " \n",
    "        derivatives[\"dW\" + str(self.L)] = dW\n",
    "        derivatives[\"db\" + str(self.L)] = db\n",
    " \n",
    "        for l in range(self.L - 1, 0, -1):\n",
    "            dZ = dAPrev * self._sigmoid_derivative(store[\"Z\" + str(l)])\n",
    "            dW = 1. / self.n * dZ.dot(store[\"O\" + str(l - 1)].T)\n",
    "            db = 1. / self.n * np.sum(dZ, axis=1, keepdims=True)\n",
    "            if l > 1:\n",
    "                dAPrev = store[\"W\" + str(l)].T.dot(dZ)\n",
    " \n",
    "            derivatives[\"dW\" + str(l)] = dW\n",
    "            derivatives[\"db\" + str(l)] = db\n",
    " \n",
    "        return derivatives\n",
    " \n",
    "    def fit(self, X, Y, learning_rate=0.01, n_iterations=2500):\n",
    "        np.random.seed(1)\n",
    " \n",
    "        self.n = X.shape[0]\n",
    " \n",
    "        self.layers_size.insert(0, X.shape[1])\n",
    " \n",
    "        self.initialize_parameters()\n",
    "        for epoch in range(1,n_iterations+1):\n",
    "            O, store = self.forward(X)\n",
    "            cost = np.squeeze(-(Y.dot(np.log(O.T)) + (1 - Y).dot(np.log(1 - O.T))) / self.n)\n",
    "            derivatives = self.backward(X, Y, store)\n",
    "\n",
    "            for l in range(1, self.L + 1):\n",
    "                self.parameters[\"W\" + str(l)] = self.parameters[\"W\" + str(l)] - learning_rate * derivatives[\"dW\" + str(l)]\n",
    "                self.parameters[\"b\" + str(l)] = self.parameters[\"b\" + str(l)] - learning_rate * derivatives[\"db\" + str(l)]\n",
    " \n",
    "            if epoch % 1000 == 0:\n",
    "                print('>> epoch=%d/%d, cost=%.3f' % (epoch, n_iterations, cost))\n",
    "                self.costs.append(cost)\n",
    " \n",
    "    def predict(self, X, Y):\n",
    "        O, cache = self.forward(X)\n",
    "        n = X.shape[0]\n",
    "        p = np.zeros((1, n))\n",
    " \n",
    "        for i in range(0, O.shape[1]):\n",
    "            if O[0, i] > 0.5:\n",
    "                p[0, i] = 1\n",
    "            else:\n",
    "                p[0, i] = 0\n",
    " \n",
    "        print(\"Accuracy: \" + str(np.sum((p == Y) / n)))\n",
    " \n",
    "    def plot_cost(self):\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(len(self.costs)), self.costs)\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"cost\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> epoch=1000/10000, cost=0.461\n",
      ">> epoch=2000/10000, cost=0.352\n",
      ">> epoch=3000/10000, cost=0.299\n",
      ">> epoch=4000/10000, cost=0.272\n",
      ">> epoch=5000/10000, cost=0.255\n",
      ">> epoch=6000/10000, cost=0.245\n",
      ">> epoch=7000/10000, cost=0.237\n",
      ">> epoch=8000/10000, cost=0.231\n",
      ">> epoch=9000/10000, cost=0.226\n",
      ">> epoch=10000/10000, cost=0.222\n",
      "\n",
      "accuracy trên tập training\n",
      "Accuracy: 0.9098901098901095\n",
      "accuracy trên tập validation\n",
      "Accuracy: 0.9473684210526316\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_size = [30, 1]\n",
    "nn = NeuralNetwork(layer_size)\n",
    "nn.fit(X_train, y_train, learning_rate=0.01, n_iterations=10000)\n",
    "print()\n",
    "print('accuracy trên tập training')\n",
    "nn.predict(X_train,y_train)\n",
    "print('accuracy trên tập validation')\n",
    "nn.predict(X_valid,y_valid)\n",
    "nn.plot_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of lab-08.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
